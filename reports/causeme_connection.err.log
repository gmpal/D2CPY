Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\asyncio\base_events.py", line 616, in run_until_complete
    return future.result()
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\nbclient\client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\ProgramData\Anaconda3\envs\d2c\lib\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
"""
This script can be used to iterate over the datasets of a particular experiment.
Below you import your function "my_method" stored in the module causeme_my_method.

Importantly, you need to first register your method on CauseMe.
Then CauseMe will return a hash code that you use below to identify which method
you used. Of course, we cannot check how you generated your results, but we can
validate a result if you upload code. Users can filter the Ranking table to only
show validated results.
"""
break # This is just to stop the execution of this cell, since it is not needed for the book

# Imports
import numpy as np
import json
import zipfile
import bz2
import time

from causeme_my_method import my_method

# Setup a python dictionary to store method hash, parameter values, and results
results = {}

################################################
# Identify method and used parameters
################################################

# Method name just for file saving
method_name = 'varmodel-python'

# Insert method hash obtained from CauseMe after method registration
results['method_sha'] = "e182a71f4e1645a1b9ede10f615df88a"

# The only parameter here is the maximum time lag
maxlags = 1

# Parameter values: These are essential to validate your results
# provided that you also uploaded code
results['parameter_values'] = "maxlags=%d" % maxlags

#################################################
# Experiment details
#################################################
# Choose model and experiment as downloaded from causeme
results['model'] = 'linear-VAR'

# Here we choose the setup with N=3 variables and time series length T=150
experimental_setup = 'N-3_T-150'
results['experiment'] = results['model'] + '_' + experimental_setup

# Adjust save name if needed
save_name = '{}_{}_{}'.format(method_name,
                              results['parameter_values'],
                              results['experiment'])

# Setup directories (adjust to your needs)
experiment_zip = 'experiments/%s.zip' % results['experiment']
results_file = 'results/%s.json.bz2' % (save_name)

#################################################

# Start of script
scores = []
pvalues = []
lags = []
runtimes = []

# (Note that runtimes on causeme are only shown for validated results, this is more for
# your own assessment here)

# Loop over all datasets within an experiment
# Important note: The datasets need to be stored in the order of their filename
# extensions, hence they are sorted here
print("Load data")
with zipfile.ZipFile(experiment_zip, "r") as zip_ref:
    for name in sorted(zip_ref.namelist()):

        print("Run {} on {}".format(method_name, name))
        data = np.loadtxt(zip_ref.open(name))

        # Runtimes for your own assessment
        start_time = time.time()

        # Run your method (adapt parameters if needed)
        val_matrix, p_matrix, lag_matrix = my_method(data, maxlags)
        runtimes.append(time.time() - start_time)

        # Now we convert the matrices to the required format
        # and write the results file
        scores.append(val_matrix.flatten())

        # pvalues and lags are recommended for a more comprehensive method evaluation,
        # but not required. Then you can leave the dictionary field empty          
        if p_matrix is not None: pvalues.append(p_matrix.flatten())
        if lag_matrix is not None: lags.append(lag_matrix.flatten())

# Store arrays as lists for json
results['scores'] = np.array(scores).tolist()
if len(pvalues) > 0: results['pvalues'] = np.array(pvalues).tolist()
if len(lags) > 0: results['lags'] = np.array(lags).tolist()
results['runtimes'] = np.array(runtimes).tolist()

# Save data
print('Writing results ...')
results_json = bytes(json.dumps(results), encoding='latin1')
with bz2.BZ2File(results_file, 'w') as mybz2:
    mybz2.write(results_json)

------------------

[1;36m  Input [1;32mIn [2][1;36m[0m
[1;33m    break # This is just to stop the execution of this cell, since it is not needed for the book[0m
[1;37m    ^[0m
[1;31mSyntaxError[0m[1;31m:[0m 'break' outside loop

SyntaxError: 'break' outside loop (13111072.py, line 11)

