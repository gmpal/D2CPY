{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D2C with GNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore the use of Graph Neural Networks for Causal Inference with D2C. Specifically, we will perform an edge classification task, where each edge will have as features the descriptors previously computed with D2C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\d2c\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Graph Neural Network: a sequence of two Graph Convolutional Layers, with Relu and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(81, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 2) # 2 classes (causal, non-causal)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to transform the descriptors dataframe to proper edge tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def create_graph_data(df):\n",
    "    # Extracting edge indices from the DataFrame\n",
    "    edge_index = torch.tensor([df['edge_source'].values, df['edge_dest'].values], dtype=torch.long)\n",
    "\n",
    "    # Creating edge features using selected columns (effca, effef, comcau, delta)\n",
    "    edge_features = torch.tensor(df[df.columns[3:-1]].values, dtype=torch.float)\n",
    "\n",
    "    # Assuming 'is_causal' column contains the labels for edges\n",
    "    edge_labels = torch.tensor(df['is_causal'].values, dtype=torch.long)\n",
    "\n",
    "    return edge_features, edge_index, edge_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading descriptors \n",
    "import pandas as pd \n",
    "data = pd.read_csv('../csv/timeseries_training.csv')\n",
    "test = data.loc[data['graph_id'] == 8]\n",
    "train = data.loc[data['graph_id'] < 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_18956\\3869780029.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  edge_index = torch.tensor([df['edge_source'].values, df['edge_dest'].values], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "\n",
    "# Iterate over unique graph_ids\n",
    "for graph_id in train['graph_id'].unique():\n",
    "    # Filter the DataFrame for rows corresponding to the current graph_id\n",
    "    graph_df = train[train['graph_id'] == graph_id]\n",
    "\n",
    "    # Create edge_features, edge_index, and edge_labels for this graph\n",
    "    edge_features, edge_index, edge_labels = create_graph_data(graph_df)\n",
    "\n",
    "    # Create a Data object for this graph\n",
    "    graph_data = Data(x=edge_features, edge_index=edge_index, y=edge_labels)\n",
    "\n",
    "    # Add to the list of graphs\n",
    "    graphs.append(graph_data)\n",
    "\n",
    "train_data = Batch.from_data_list(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our network here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and optimizer\n",
    "model = GNN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data.x, train_data.edge_index)\n",
    "    loss = F.cross_entropy(out, train_data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_edge_features, eval_edge_index, eval_edge_labels = create_graph_data(test)\n",
    "\n",
    "# Create a Data object for this graph\n",
    "eval_graph_data = Data(x=eval_edge_features, edge_index=eval_edge_index, y=eval_edge_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our network on 1 unseen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels:\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "Real Labels:\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions using the evaluation data\n",
    "with torch.no_grad():\n",
    "    predictions = model(eval_graph_data.x, eval_graph_data.edge_index)\n",
    "\n",
    "# Convert the predictions to probabilities using the softmax function\n",
    "probs = F.softmax(predictions, dim=1)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_labels = torch.argmax(probs, dim=1)\n",
    "\n",
    "# Print the Predicted Labels\n",
    "print(\"Predicted Labels:\")\n",
    "print(predicted_labels)\n",
    "print(\"Real Labels:\")\n",
    "print(eval_edge_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}