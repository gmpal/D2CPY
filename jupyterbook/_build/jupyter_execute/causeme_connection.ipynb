{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causeme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CauseMe platform, hosted at https://causeme.uv.es/, is an online benchmarking tool focused on causal discovery methods, specifically designed to detect causal associations in time series datasets. These datasets may relate to intricate systems like the Earth's ecology or the human brain, where determining causality can be highly complex. CauseMe offers ground truth benchmark datasets, containing both synthetic models that emulate real challenges and real-world datasets with known causal structures, varying in complexity, dimensionality, and sophistication. Method developers can contribute by developing new methods and assessing their performance on available datasets, or by providing multivariate time series data with known causal ground truth. Within the platform, synthetic model data are provided to address a multitude of real-world challenges, and developers can upload their predictions of causal connections. The platform then evaluates and ranks these methods using different performance metrics. CauseMe serves as a valuable tool for researchers and scholars by providing access to data, insights, and evaluation techniques that promote advancements in causal discovery across various fields."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causeme and D2C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D2CPY could find substantial utility by integrating with the platform's vast benchmark datasets for causal discovery. By leveraging CauseMe’s ground truth datasets and evaluation metrics, developers and data scientists using D2CPY can validate and refine their causal discovery methods. The platform's diverse datasets, encompassing both real-world and synthetic challenges, could help in testing the robustness of the D2C algorithm implemented in D2CPY."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing the code that we'll be exploring together, library users can seamlessly connect their D2CPY-based causal discovery methods to CauseMe. This will allow them to run their algorithms on CauseMe's real and synthetic datasets, compare the outcomes with ground truth causal structures, and gain valuable insights into the effectiveness and robustness of their approaches. The code bridges the functionality of D2CPY with CauseMe’s evaluation environment, streamlining the process of testing, validation, and enhancement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the user must register her method on the causemeplatform, to receive a `method_sha` that needs to be included in the submission. <br>\n",
    "For submitting to the platform, a wrapper around a function `my_method()` is provided by the D2C platform. <br>\n",
    "Therefore, the user can focus on the implementation of the aforementioned function. A minimal example is shown below. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This file must contain a function called my_method that triggers all the steps \n",
    "required in order to obtain\n",
    "\n",
    " *val_matrix: mandatory, (N, N) matrix of scores for links\n",
    " *p_matrix: optional, (N, N) matrix of p-values for links; if not available, \n",
    "            None must be returned\n",
    " *lag_matrix: optional, (N, N) matrix of time lags for links; if not available, \n",
    "              None must be returned\n",
    "\n",
    "Zip this file (together with other necessary files if you have further handmade \n",
    "packages) to upload as a code.zip. You do NOT need to upload files for packages \n",
    "that can be imported via pip or conda repositories. Once you upload your code, \n",
    "we are able to validate results including runtime estimates on the same machine.\n",
    "These results are then marked as \"Validated\" and users can use filters to only \n",
    "show validated results.\n",
    "\n",
    "Shown here is a vector-autoregressive model estimator as a simple method.\n",
    "\"\"\"\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# import numpy as np\n",
    "# from d2c.simulatedTimeSeries import SimulatedTimeSeries\n",
    "# from d2c.D2C import D2C\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Your method must be called 'my_method'\n",
    "# Describe all parameters (except for 'data') in the method registration on CauseMe\n",
    "def my_method(data, maxlags=1, correct_pvalues=True):\n",
    "\n",
    "    # Input data is of shape (time, variables)\n",
    "    T, N = data.shape\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "\n",
    "    d2c_test = D2C([None],[data_df])\n",
    "    X_test = d2c_test.compute_descriptors_no_dags()\n",
    "\n",
    "    training_data = pd.read_csv('./timeseries_training.csv')\n",
    "\n",
    "    X_train = training_data.drop(['graph_id', 'edge_source', 'edge_dest', 'is_causal'], axis=1)\n",
    "    y_train = training_data['is_causal']\n",
    "\n",
    "    test_df = pd.DataFrame(X_test).drop(['graph_id', 'edge_source', 'edge_dest'], axis=1)\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(test_df)\n",
    "\n",
    "    returned = pd.concat([pd.DataFrame(X_test), pd.DataFrame(y_pred, columns=['is_causal'])], axis=1)\n",
    "    of_interest = returned[['edge_source', 'edge_dest','is_causal']]\n",
    "    \n",
    "\n",
    "    val_matrix = np.zeros((N, N), dtype='float32')\n",
    "\n",
    "    for index, row in of_interest.iterrows():\n",
    "        source = row['edge_source']\n",
    "        dest = row['edge_dest']\n",
    "        weight = row['is_causal']\n",
    "        val_matrix[source, dest] = weight\n",
    "\n",
    "    return val_matrix, None, None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper code, that requires minor modifications, can be found below. Datasets in the `experiment` folder must be downloaded from the platform as necessary. The wrapper will produce an output file in the `results` folder that needs to be uploaded on the causeme platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# This script can be used to iterate over the datasets of a particular experiment.\n",
    "# Below you import your function \"my_method\" stored in the module causeme_my_method.\n",
    "\n",
    "# Importantly, you need to first register your method on CauseMe.\n",
    "# Then CauseMe will return a hash code that you use below to identify which method\n",
    "# you used. Of course, we cannot check how you generated your results, but we can\n",
    "# validate a result if you upload code. Users can filter the Ranking table to only\n",
    "# show validated results.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# # Imports\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import zipfile\n",
    "# import bz2\n",
    "# import time\n",
    "\n",
    "# from causeme_my_method import my_method\n",
    "\n",
    "# # Setup a python dictionary to store method hash, parameter values, and results\n",
    "# results = {}\n",
    "\n",
    "# ################################################\n",
    "# # Identify method and used parameters\n",
    "# ################################################\n",
    "\n",
    "# # Method name just for file saving\n",
    "# method_name = 'varmodel-python'\n",
    "\n",
    "# # Insert method hash obtained from CauseMe after method registration\n",
    "# results['method_sha'] = \"e182a71f4e1645a1b9ede10f615df88a\"\n",
    "\n",
    "# # The only parameter here is the maximum time lag\n",
    "# maxlags = 1\n",
    "\n",
    "# # Parameter values: These are essential to validate your results\n",
    "# # provided that you also uploaded code\n",
    "# results['parameter_values'] = \"maxlags=%d\" % maxlags\n",
    "\n",
    "# #################################################\n",
    "# # Experiment details\n",
    "# #################################################\n",
    "# # Choose model and experiment as downloaded from causeme\n",
    "# results['model'] = 'linear-VAR'\n",
    "\n",
    "# # Here we choose the setup with N=3 variables and time series length T=150\n",
    "# experimental_setup = 'N-3_T-150'\n",
    "# results['experiment'] = results['model'] + '_' + experimental_setup\n",
    "\n",
    "# # Adjust save name if needed\n",
    "# save_name = '{}_{}_{}'.format(method_name,\n",
    "#                               results['parameter_values'],\n",
    "#                               results['experiment'])\n",
    "\n",
    "# # Setup directories (adjust to your needs)\n",
    "# experiment_zip = 'experiments/%s.zip' % results['experiment']\n",
    "# results_file = 'results/%s.json.bz2' % (save_name)\n",
    "\n",
    "# #################################################\n",
    "\n",
    "# # Start of script\n",
    "# scores = []\n",
    "# pvalues = []\n",
    "# lags = []\n",
    "# runtimes = []\n",
    "\n",
    "# # (Note that runtimes on causeme are only shown for validated results, this is more for\n",
    "# # your own assessment here)\n",
    "\n",
    "# # Loop over all datasets within an experiment\n",
    "# # Important note: The datasets need to be stored in the order of their filename\n",
    "# # extensions, hence they are sorted here\n",
    "# print(\"Load data\")\n",
    "# with zipfile.ZipFile(experiment_zip, \"r\") as zip_ref:\n",
    "#     for name in sorted(zip_ref.namelist()):\n",
    "\n",
    "#         print(\"Run {} on {}\".format(method_name, name))\n",
    "#         data = np.loadtxt(zip_ref.open(name))\n",
    "\n",
    "#         # Runtimes for your own assessment\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         # Run your method (adapt parameters if needed)\n",
    "#         val_matrix, p_matrix, lag_matrix = my_method(data, maxlags)\n",
    "#         runtimes.append(time.time() - start_time)\n",
    "\n",
    "#         # Now we convert the matrices to the required format\n",
    "#         # and write the results file\n",
    "#         scores.append(val_matrix.flatten())\n",
    "\n",
    "#         # pvalues and lags are recommended for a more comprehensive method evaluation,\n",
    "#         # but not required. Then you can leave the dictionary field empty          \n",
    "#         if p_matrix is not None: pvalues.append(p_matrix.flatten())\n",
    "#         if lag_matrix is not None: lags.append(lag_matrix.flatten())\n",
    "\n",
    "# # Store arrays as lists for json\n",
    "# results['scores'] = np.array(scores).tolist()\n",
    "# if len(pvalues) > 0: results['pvalues'] = np.array(pvalues).tolist()\n",
    "# if len(lags) > 0: results['lags'] = np.array(lags).tolist()\n",
    "# results['runtimes'] = np.array(runtimes).tolist()\n",
    "\n",
    "# # Save data\n",
    "# print('Writing results ...')\n",
    "# results_json = bytes(json.dumps(results), encoding='latin1')\n",
    "# with bz2.BZ2File(results_file, 'w') as mybz2:\n",
    "#     mybz2.write(results_json)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further instruction, the user is encouraged to look at the extensive causeme documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}