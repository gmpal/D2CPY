{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script can be used to iterate over the datasets of a particular experiment.\n",
    "Below you import your function \"my_method\" stored in the module causeme_my_method.\n",
    "\n",
    "Importantly, you need to first register your method on CauseMe.\n",
    "Then CauseMe will return a hash code that you use below to identify which method\n",
    "you used. Of course, we cannot check how you generated your results, but we can\n",
    "validate a result if you upload code. Users can filter the Ranking table to only\n",
    "show validated results.\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "import bz2\n",
    "import time\n",
    "\n",
    "from causeme_my_method import my_method\n",
    "\n",
    "# Setup a python dictionary to store method hash, parameter values, and results\n",
    "results = {}\n",
    "\n",
    "################################################\n",
    "# Identify method and used parameters\n",
    "################################################\n",
    "\n",
    "# Method name just for file saving\n",
    "method_name = 'd2c_basic'\n",
    "\n",
    "# Insert method hash obtained from CauseMe after method registration\n",
    "results['method_sha'] = \"e182a71f4e1645a1b9ede10f615df88a\"\n",
    "\n",
    "# The only parameter here is the maximum time lag\n",
    "maxlags = 5\n",
    "\n",
    "# Parameter values: These are essential to validate your results\n",
    "# provided that you also uploaded code\n",
    "results['parameter_values'] = \"maxlags=%d\" % maxlags\n",
    "\n",
    "#################################################\n",
    "# Experiment details\n",
    "#################################################\n",
    "# Choose model and experiment as downloaded from causeme\n",
    "results['model'] = 'linear-VAR'\n",
    "\n",
    "# Here we choose the setup with N=3 variables and time series length T=150\n",
    "experimental_setup = 'N-3_T-150'\n",
    "results['experiment'] = results['model'] + '_' + experimental_setup\n",
    "\n",
    "# Adjust save name if needed\n",
    "save_name = '{}_{}_{}'.format(method_name,\n",
    "                              results['parameter_values'],\n",
    "                              results['experiment'])\n",
    "\n",
    "# Setup directories (adjust to your needs)\n",
    "experiment_zip = 'experiments/%s.zip' % results['experiment']\n",
    "results_file = 'results/%s.json.bz2' % (save_name)\n",
    "\n",
    "#################################################\n",
    "\n",
    "# Start of script\n",
    "scores = []\n",
    "pvalues = []\n",
    "lags = []\n",
    "runtimes = []\n",
    "\n",
    "# (Note that runtimes on causeme are only shown for validated results, this is more for\n",
    "# your own assessment here)\n",
    "\n",
    "# Loop over all datasets within an experiment\n",
    "# Important note: The datasets need to be stored in the order of their filename\n",
    "# extensions, hence they are sorted here\n",
    "print(\"Load data\")\n",
    "with zipfile.ZipFile(experiment_zip, \"r\") as zip_ref:\n",
    "    for name in sorted(zip_ref.namelist()):\n",
    "\n",
    "        print(\"Run {} on {}\".format(method_name, name))\n",
    "        data = np.loadtxt(zip_ref.open(name))\n",
    "\n",
    "        # Runtimes for your own assessment\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run your method (adapt parameters if needed)\n",
    "        val_matrix, p_matrix, lag_matrix = my_method(data, maxlags)\n",
    "        runtimes.append(time.time() - start_time)\n",
    "\n",
    "        # Now we convert the matrices to the required format\n",
    "        # and write the results file\n",
    "        scores.append(val_matrix.flatten())\n",
    "\n",
    "        # pvalues and lags are recommended for a more comprehensive method evaluation,\n",
    "        # but not required. Then you can leave the dictionary field empty          \n",
    "        if p_matrix is not None: pvalues.append(p_matrix.flatten())\n",
    "        if lag_matrix is not None: lags.append(lag_matrix.flatten())\n",
    "\n",
    "# Store arrays as lists for json\n",
    "results['scores'] = np.array(scores).tolist()\n",
    "if len(pvalues) > 0: results['pvalues'] = np.array(pvalues).tolist()\n",
    "if len(lags) > 0: results['lags'] = np.array(lags).tolist()\n",
    "results['runtimes'] = np.array(runtimes).tolist()\n",
    "\n",
    "# Save data\n",
    "print('Writing results ...')\n",
    "results_json = bytes(json.dumps(results), encoding='latin1')\n",
    "with bz2.BZ2File(results_file, 'w') as mybz2:\n",
    "    mybz2.write(results_json)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
