{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file must contain a function called my_method that triggers all the steps \n",
    "required in order to obtain\n",
    "\n",
    " *val_matrix: mandatory, (N, N) matrix of scores for links\n",
    " *p_matrix: optional, (N, N) matrix of p-values for links; if not available, \n",
    "            None must be returned\n",
    " *lag_matrix: optional, (N, N) matrix of time lags for links; if not available, \n",
    "              None must be returned\n",
    "\n",
    "Zip this file (together with other necessary files if you have further handmade \n",
    "packages) to upload as a code.zip. You do NOT need to upload files for packages \n",
    "that can be imported via pip or conda repositories. Once you upload your code, \n",
    "we are able to validate results including runtime estimates on the same machine.\n",
    "These results are then marked as \"Validated\" and users can use filters to only \n",
    "show validated results.\n",
    "\n",
    "Shown here is a vector-autoregressive model estimator as a simple method.\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from d2c.simulatedTimeSeries import SimulatedTimeSeries\n",
    "from d2c.D2C import D2C\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your method must be called 'my_method'\n",
    "# Describe all parameters (except for 'data') in the method registration on CauseMe\n",
    "def my_method(data, maxlags=1, correct_pvalues=True):\n",
    "\n",
    "    # Input data is of shape (time, variables)\n",
    "    T, N = data.shape\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "\n",
    "    d2c_test = D2C([None],[data_df])\n",
    "    X_test = d2c_test.compute_descriptors_no_dags()\n",
    "    print(X_test)\n",
    "    training_data = pd.read_csv('./descriptors.csv')\n",
    "\n",
    "    X_train = training_data.drop(['graph_id', 'edge_source', 'edge_dest', 'is_causal'], axis=1)\n",
    "    y_train = training_data['is_causal']\n",
    "\n",
    "    test_df = pd.DataFrame(X_test).drop(['graph_id', 'edge_source', 'edge_dest'], axis=1)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict_proba(test_df)[1]\n",
    "\n",
    "    returned = pd.concat([pd.DataFrame(X_test), pd.DataFrame(y_pred, columns=['is_causal'])], axis=1)\n",
    "    of_interest = returned[['edge_source', 'edge_dest','is_causal']]\n",
    "    \n",
    "\n",
    "    val_matrix = np.zeros((N, N), dtype='float32')\n",
    "\n",
    "    for index, row in of_interest.iterrows():\n",
    "        source =int(row['edge_source'])\n",
    "        dest = int(row['edge_dest'])\n",
    "        weight = row['is_causal']\n",
    "        print(f\"source: {source}, dest: {dest}, weight: {weight}\")\n",
    "        val_matrix[source, dest] = weight\n",
    "\n",
    "    return val_matrix, None, None\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
