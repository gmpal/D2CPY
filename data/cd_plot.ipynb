{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Hassan Ismail Fawaz <hassan.ismail-fawaz@uha.fr>\n",
    "#         Germain Forestier <germain.forestier@uha.fr>\n",
    "#         Jonathan Weber <jonathan.weber@uha.fr>\n",
    "#         Lhassane Idoumghar <lhassane.idoumghar@uha.fr>\n",
    "#         Pierre-Alain Muller <pierre-alain.muller@uha.fr>\n",
    "# License: GPL3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "import operator\n",
    "import math\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import friedmanchisquare\n",
    "import networkx\n",
    "\n",
    "# inspired from orange3 https://docs.orange.biolab.si/3/data-mining-library/reference/evaluation.cd.html\n",
    "def graph_ranks(avranks, names, p_values, cd=None, cdmethod=None, lowv=None, highv=None,\n",
    "                width=6, textspace=1, reverse=False, filename=None, labels=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Draws a CD graph, which is used to display  the differences in methods'\n",
    "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
    "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
    "\n",
    "    Needs matplotlib to work.\n",
    "\n",
    "    The image is ploted on `plt` imported using\n",
    "    `import matplotlib.pyplot as plt`.\n",
    "\n",
    "    Args:\n",
    "        avranks (list of float): average ranks of methods.\n",
    "        names (list of str): names of methods.\n",
    "        cd (float): Critical difference used for statistically significance of\n",
    "            difference between methods.\n",
    "        cdmethod (int, optional): the method that is compared with other methods\n",
    "            If omitted, show pairwise comparison of methods\n",
    "        lowv (int, optional): the lowest shown rank\n",
    "        highv (int, optional): the highest shown rank\n",
    "        width (int, optional): default width in inches (default: 6)\n",
    "        textspace (int, optional): space on figure sides (in inches) for the\n",
    "            method names (default: 1)\n",
    "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
    "            right (default: `False`)\n",
    "        filename (str, optional): output file name (with extension). If not\n",
    "            given, the function does not write a file.\n",
    "        labels (bool, optional): if set to `True`, the calculated avg rank\n",
    "        values will be displayed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
    "\n",
    "    width = float(width)\n",
    "    textspace = float(textspace)\n",
    "\n",
    "    def nth(l, n):\n",
    "        \"\"\"\n",
    "        Returns only nth elemnt in a list.\n",
    "        \"\"\"\n",
    "        n = lloc(l, n)\n",
    "        return [a[n] for a in l]\n",
    "\n",
    "    def lloc(l, n):\n",
    "        \"\"\"\n",
    "        List location in list of list structure.\n",
    "        Enable the use of negative locations:\n",
    "        -1 is the last element, -2 second last...\n",
    "        \"\"\"\n",
    "        if n < 0:\n",
    "            return len(l[0]) + n\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def mxrange(lr):\n",
    "        \"\"\"\n",
    "        Multiple xranges. Can be used to traverse matrices.\n",
    "        This function is very slow due to unknown number of\n",
    "        parameters.\n",
    "\n",
    "        >>> mxrange([3,5])\n",
    "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "\n",
    "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
    "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
    "\n",
    "        \"\"\"\n",
    "        if not len(lr):\n",
    "            yield ()\n",
    "        else:\n",
    "            # it can work with single numbers\n",
    "            index = lr[0]\n",
    "            if isinstance(index, int):\n",
    "                index = [index]\n",
    "            for a in range(*index):\n",
    "                for b in mxrange(lr[1:]):\n",
    "                    yield tuple([a] + list(b))\n",
    "\n",
    "    def print_figure(fig, *args, **kwargs):\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        canvas.print_figure(*args, **kwargs)\n",
    "\n",
    "    sums = avranks\n",
    "\n",
    "    nnames = names\n",
    "    ssums = sums\n",
    "\n",
    "    if lowv is None:\n",
    "        lowv = min(1, int(math.floor(min(ssums))))\n",
    "    if highv is None:\n",
    "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
    "\n",
    "    cline = 0.4\n",
    "\n",
    "    k = len(sums)\n",
    "\n",
    "    lines = None\n",
    "\n",
    "    linesblank = 0\n",
    "    scalewidth = width - 2 * textspace\n",
    "\n",
    "    def rankpos(rank):\n",
    "        if not reverse:\n",
    "            a = rank - lowv\n",
    "        else:\n",
    "            a = highv - rank\n",
    "        return textspace + scalewidth / (highv - lowv) * a\n",
    "\n",
    "    distanceh = 0.25\n",
    "\n",
    "    cline += distanceh\n",
    "\n",
    "    # calculate height needed height of an image\n",
    "    minnotsignificant = max(2 * 0.2, linesblank)\n",
    "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    fig.set_facecolor('white')\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    hf = 1. / height  # height factor\n",
    "    wf = 1. / width\n",
    "\n",
    "    def hfl(l):\n",
    "        return [a * hf for a in l]\n",
    "\n",
    "    def wfl(l):\n",
    "        return [a * wf for a in l]\n",
    "\n",
    "    # Upper left corner is (0,0).\n",
    "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(1, 0)\n",
    "\n",
    "    def line(l, color='k', **kwargs):\n",
    "        \"\"\"\n",
    "        Input is a list of pairs of points.\n",
    "        \"\"\"\n",
    "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
    "\n",
    "    def text(x, y, s, *args, **kwargs):\n",
    "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
    "\n",
    "    line([(textspace, cline), (width - textspace, cline)], linewidth=2)\n",
    "\n",
    "    bigtick = 0.3\n",
    "    smalltick = 0.15\n",
    "    linewidth = 2.0\n",
    "    linewidth_sign = 4.0\n",
    "\n",
    "    tick = None\n",
    "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
    "        tick = smalltick\n",
    "        if a == int(a):\n",
    "            tick = bigtick\n",
    "        line([(rankpos(a), cline - tick / 2),\n",
    "              (rankpos(a), cline)],\n",
    "             linewidth=2)\n",
    "\n",
    "    for a in range(lowv, highv + 1):\n",
    "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
    "             ha=\"center\", va=\"bottom\", size=16)\n",
    "\n",
    "    k = len(ssums)\n",
    "\n",
    "    def filter_names(name):\n",
    "        return name\n",
    "\n",
    "    space_between_names = 0.24\n",
    "\n",
    "    for i in range(math.ceil(k / 2)):\n",
    "        chei = cline + minnotsignificant + i * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace - 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"right\", va=\"center\", size=10)\n",
    "        text(textspace - 0.2, chei, filter_names(nnames[i]), ha=\"right\", va=\"center\", size=16)\n",
    "\n",
    "    for i in range(math.ceil(k / 2), k):\n",
    "        chei = cline + minnotsignificant + (k - i - 1) * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace + scalewidth + 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + scalewidth - 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"left\", va=\"center\", size=10)\n",
    "        text(textspace + scalewidth + 0.2, chei, filter_names(nnames[i]),\n",
    "             ha=\"left\", va=\"center\", size=16)\n",
    "\n",
    "    # no-significance lines\n",
    "    def draw_lines(lines, side=0.05, height=0.1):\n",
    "        start = cline + 0.2\n",
    "\n",
    "        for l, r in lines:\n",
    "            line([(rankpos(ssums[l]) - side, start),\n",
    "                  (rankpos(ssums[r]) + side, start)],\n",
    "                 linewidth=linewidth_sign)\n",
    "            start += height\n",
    "            print('drawing: ', l, r)\n",
    "\n",
    "    # draw_lines(lines)\n",
    "    start = cline + 0.2\n",
    "    side = -0.02\n",
    "    height = 0.1\n",
    "\n",
    "    # draw no significant lines\n",
    "    # get the cliques\n",
    "    cliques = form_cliques(p_values, nnames)\n",
    "    i = 1\n",
    "    achieved_half = False\n",
    "    print(nnames)\n",
    "    for clq in cliques:\n",
    "        if len(clq) == 1:\n",
    "            continue\n",
    "        print(clq)\n",
    "        min_idx = np.array(clq).min()\n",
    "        max_idx = np.array(clq).max()\n",
    "        if min_idx >= len(nnames) / 2 and achieved_half == False:\n",
    "            start = cline + 0.25\n",
    "            achieved_half = True\n",
    "        line([(rankpos(ssums[min_idx]) - side, start),\n",
    "              (rankpos(ssums[max_idx]) + side, start)],\n",
    "             linewidth=linewidth_sign)\n",
    "        start += height\n",
    "\n",
    "\n",
    "def form_cliques(p_values, nnames):\n",
    "    \"\"\"\n",
    "    This method forms the cliques\n",
    "    \"\"\"\n",
    "    # first form the numpy matrix data\n",
    "    m = len(nnames)\n",
    "    g_data = np.zeros((m, m), dtype=np.int64)\n",
    "    for p in p_values:\n",
    "        if p[3] == False:\n",
    "            i = np.where(nnames == p[0])[0][0]\n",
    "            j = np.where(nnames == p[1])[0][0]\n",
    "            min_i = min(i, j)\n",
    "            max_j = max(i, j)\n",
    "            g_data[min_i, max_j] = 1\n",
    "\n",
    "    g = networkx.Graph(g_data)\n",
    "    return networkx.find_cliques(g)\n",
    "\n",
    "\n",
    "def draw_cd_diagram(df_perf=None, alpha=0.05, title=None, labels=False):\n",
    "    \"\"\"\n",
    "    Draws the critical difference diagram given the list of pairwise classifiers that are\n",
    "    significant or not\n",
    "    \"\"\"\n",
    "    p_values, average_ranks, _ = wilcoxon_holm(df_perf=df_perf, alpha=alpha)\n",
    "\n",
    "    print(average_ranks)\n",
    "\n",
    "    for p in p_values:\n",
    "        print(p)\n",
    "\n",
    "\n",
    "    graph_ranks(average_ranks.values, average_ranks.keys(), p_values,\n",
    "                cd=None, reverse=True, width=9, textspace=1.5, labels=labels)\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 22,\n",
    "        }\n",
    "    if title:\n",
    "        plt.title(title,fontdict=font, y=0.9, x=0.5)\n",
    "    plt.savefig(f'cd-diagram-{title}.png',bbox_inches='tight')\n",
    "\n",
    "def wilcoxon_holm(alpha=0.05, df_perf=None):\n",
    "    \"\"\"\n",
    "    Applies the wilcoxon signed rank test between each pair of algorithm and then use Holm\n",
    "    to reject the null's hypothesis\n",
    "    \"\"\"\n",
    "    print(pd.unique(df_perf['Model']))\n",
    "    # count the number of tested datasets per classifier\n",
    "    df_counts = pd.DataFrame({'count': df_perf.groupby(\n",
    "        ['Model']).size()}).reset_index()\n",
    "    # get the maximum number of tested datasets\n",
    "    print(df_counts)\n",
    "    max_nb_datasets = df_counts['count'].max()\n",
    "    # get the list of classifiers who have been tested on nb_max_datasets\n",
    "    classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n",
    "                       ['Model'])\n",
    "    # test the null hypothesis using friedman before doing a post-hoc analysis\n",
    "    friedman_p_value = friedmanchisquare(*(\n",
    "        np.array(df_perf.loc[df_perf['Model'] == c]['Score'])\n",
    "        for c in classifiers))[1]\n",
    "    if friedman_p_value >= alpha:\n",
    "        # then the null hypothesis over the entire classifiers cannot be rejected\n",
    "        print('the null hypothesis over the entire classifiers cannot be rejected')\n",
    "        exit()\n",
    "    # get the number of classifiers\n",
    "    m = len(classifiers)\n",
    "    # init array that contains the p-values calculated by the Wilcoxon signed rank test\n",
    "    p_values = []\n",
    "    # loop through the algorithms to compare pairwise\n",
    "    for i in range(m - 1):\n",
    "        # get the name of classifier one\n",
    "        classifier_1 = classifiers[i]\n",
    "        # get the performance of classifier one\n",
    "        perf_1 = np.array(df_perf.loc[df_perf['Model'] == classifier_1]['Score']\n",
    "                          , dtype=np.float64)\n",
    "        for j in range(i + 1, m):\n",
    "            # get the name of the second classifier\n",
    "            classifier_2 = classifiers[j]\n",
    "            # get the performance of classifier one\n",
    "            perf_2 = np.array(df_perf.loc[df_perf['Model'] == classifier_2]\n",
    "                              ['Score'], dtype=np.float64)\n",
    "            # calculate the p_value\n",
    "            p_value = wilcoxon(perf_1, perf_2, zero_method='pratt')[1]\n",
    "            # appen to the list\n",
    "            p_values.append((classifier_1, classifier_2, p_value, False))\n",
    "    # get the number of hypothesis\n",
    "    k = len(p_values)\n",
    "    # sort the list in acsending manner of p-value\n",
    "    p_values.sort(key=operator.itemgetter(2))\n",
    "\n",
    "    # loop through the hypothesis\n",
    "    for i in range(k):\n",
    "        # correct alpha with holm\n",
    "        new_alpha = float(alpha / (k - i))\n",
    "        # test if significant after holm's correction of alpha\n",
    "        if p_values[i][2] <= new_alpha:\n",
    "            p_values[i] = (p_values[i][0], p_values[i][1], p_values[i][2], True)\n",
    "        else:\n",
    "            # stop\n",
    "            break\n",
    "    # compute the average ranks to be returned (useful for drawing the cd diagram)\n",
    "    # sort the dataframe of performances\n",
    "    sorted_df_perf = df_perf.loc[df_perf['Model'].isin(classifiers)]. \\\n",
    "        sort_values(['Model', 'dataset_name'])\n",
    "    # get the rank data\n",
    "    rank_data = np.array(sorted_df_perf['Score']).reshape(m, max_nb_datasets)\n",
    "    print(rank_data)\n",
    "    # create the data frame containg the accuracies\n",
    "    df_ranks = pd.DataFrame(data=rank_data, index=np.sort(classifiers), columns=\n",
    "    np.unique(sorted_df_perf['dataset_name']))\n",
    "\n",
    "    # number of wins\n",
    "    dfff = df_ranks.rank(ascending=False)\n",
    "    print(dfff[dfff == 1.0].sum(axis=1))\n",
    "\n",
    "    # average the ranks\n",
    "    average_ranks = df_ranks.rank(ascending=False).mean(axis=1).sort_values(ascending=False)\n",
    "    # return the p-values and the average ranks\n",
    "    return p_values, average_ranks, max_nb_datasets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('100_known_ts_all_scores.csv', index_col=False)\n",
    "\n",
    "accuracy_df = df[df[\"Metric\"] == \"accuracy\"]\n",
    "precision_df = df[df[\"Metric\"] == \"precision\"]\n",
    "recall_df = df[df[\"Metric\"] == \"recall\"]\n",
    "f1_df = df[df[\"Metric\"] == \"f1\"]\n",
    "balanced_error_df = df[df[\"Metric\"] == \"balanced_error\"]\n",
    "auc_df = df[df[\"Metric\"] == \"auc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1497, 1498, 1499])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make 6 concats of np.arange(1500)\n",
    "concats = [np.arange(1500)]*6\n",
    "#concatenate them\n",
    "concats = np.concatenate(concats)\n",
    "concats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57066/3574614329.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  balanced_error_df['Metric'] = concats\n",
      "/tmp/ipykernel_57066/3574614329.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  balanced_error_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
      "/tmp/ipykernel_57066/3574614329.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  accuracy_df['Metric'] = concats\n",
      "/tmp/ipykernel_57066/3574614329.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  accuracy_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
      "/tmp/ipykernel_57066/3574614329.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  precision_df['Metric'] = concats\n",
      "/tmp/ipykernel_57066/3574614329.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  precision_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
      "/tmp/ipykernel_57066/3574614329.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recall_df['Metric'] = concats\n",
      "/tmp/ipykernel_57066/3574614329.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recall_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
      "/tmp/ipykernel_57066/3574614329.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  f1_df['Metric'] = concats\n",
      "/tmp/ipykernel_57066/3574614329.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  f1_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (9000) does not match length of index (7500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m f1_df[\u001b[39m'\u001b[39m\u001b[39mMetric\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m concats\n\u001b[1;32m     14\u001b[0m f1_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mMetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mdataset_name\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m auc_df[\u001b[39m'\u001b[39;49m\u001b[39mMetric\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m concats\n\u001b[1;32m     17\u001b[0m auc_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mMetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mdataset_name\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2cpy/lib/python3.8/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2cpy/lib/python3.8/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/d2cpy/lib/python3.8/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4916\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2cpy/lib/python3.8/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (9000) does not match length of index (7500)"
     ]
    }
   ],
   "source": [
    "balanced_error_df['Metric'] = concats\n",
    "balanced_error_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
    "\n",
    "accuracy_df['Metric'] = concats\n",
    "accuracy_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
    "\n",
    "precision_df['Metric'] = concats\n",
    "precision_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
    "\n",
    "recall_df['Metric'] = concats\n",
    "recall_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
    "\n",
    "f1_df['Metric'] = concats\n",
    "f1_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
    "\n",
    "# auc_df['Metric'] = concats\n",
    "# auc_df.rename(columns={'Metric': 'dataset_name'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DYNOTEARS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DYNOTEARS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DYNOTEARS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DYNOTEARS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.473077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DYNOTEARS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52474</th>\n",
       "      <td>D2C1</td>\n",
       "      <td>1495</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52480</th>\n",
       "      <td>D2C1</td>\n",
       "      <td>1496</td>\n",
       "      <td>0.061538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52486</th>\n",
       "      <td>D2C1</td>\n",
       "      <td>1497</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52492</th>\n",
       "      <td>D2C1</td>\n",
       "      <td>1498</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52498</th>\n",
       "      <td>D2C1</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  dataset_name     Score\n",
       "4      DYNOTEARS             0  0.500000\n",
       "10     DYNOTEARS             1  0.527778\n",
       "16     DYNOTEARS             2  0.488889\n",
       "22     DYNOTEARS             3  0.473077\n",
       "28     DYNOTEARS             4  0.527778\n",
       "...          ...           ...       ...\n",
       "52474       D2C1          1495  0.233333\n",
       "52480       D2C1          1496  0.061538\n",
       "52486       D2C1          1497  0.208333\n",
       "52492       D2C1          1498  0.125000\n",
       "52498       D2C1          1499  0.325000\n",
       "\n",
       "[9000 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DYNOTEARS' 'Granger' 'PCMCI' 'VAR' 'VARLiNGAM' 'D2C1']\n",
      "       Model  count\n",
      "0       D2C1   1500\n",
      "1  DYNOTEARS   1500\n",
      "2    Granger   1500\n",
      "3      PCMCI   1500\n",
      "4        VAR   1500\n",
      "5  VARLiNGAM   1500\n",
      "[[0.17777778 0.22222222 0.22222222 ... 0.20833333 0.125      0.325     ]\n",
      " [0.5        0.52777778 0.48888889 ... 0.55833333 0.56666667 0.56666667]\n",
      " [0.65       0.51111111 0.47777778 ... 0.51666667 0.46666667 0.46666667]\n",
      " [0.58333333 0.54444444 0.54444444 ... 0.64166667 0.65       0.61666667]\n",
      " [0.65555556 0.49444444 0.5        ... 0.35833333 0.35       0.15      ]\n",
      " [0.52777778 0.51111111 0.55       ... 0.1        0.10833333 0.08333333]]\n",
      "D2C1          86.0\n",
      "DYNOTEARS    173.0\n",
      "Granger      603.0\n",
      "PCMCI        386.0\n",
      "VAR           69.0\n",
      "VARLiNGAM    122.0\n",
      "dtype: float64\n",
      "D2C1         4.922000\n",
      "VARLiNGAM    4.506000\n",
      "VAR          3.354333\n",
      "DYNOTEARS    2.987333\n",
      "PCMCI        2.814000\n",
      "Granger      2.416333\n",
      "dtype: float64\n",
      "('D2C1', 'Granger', 3.391313703421085e-199, True)\n",
      "('D2C1', 'DYNOTEARS', 6.466113822152697e-190, True)\n",
      "('D2C1', 'VAR', 4.7805419120490266e-172, True)\n",
      "('D2C1', 'PCMCI', 2.868075025464356e-169, True)\n",
      "('Granger', 'VARLiNGAM', 2.855513190466724e-168, True)\n",
      "('VAR', 'VARLiNGAM', 1.188321950209166e-142, True)\n",
      "('PCMCI', 'VARLiNGAM', 5.61008760317419e-135, True)\n",
      "('DYNOTEARS', 'VARLiNGAM', 5.782746915389934e-106, True)\n",
      "('Granger', 'VAR', 4.496453852363913e-86, True)\n",
      "('DYNOTEARS', 'Granger', 7.11482128311957e-30, True)\n",
      "('Granger', 'PCMCI', 6.173999769593117e-24, True)\n",
      "('DYNOTEARS', 'VAR', 4.458313190674245e-14, True)\n",
      "('PCMCI', 'VAR', 6.213383798689009e-12, True)\n",
      "('D2C1', 'VARLiNGAM', 6.519857581324996e-11, True)\n",
      "('DYNOTEARS', 'PCMCI', 0.01648890966804811, True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['D2C1', 'VARLiNGAM', 'VAR', 'DYNOTEARS', 'PCMCI', 'Granger'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "draw_cd_diagram(df_perf=balanced_error_df, title='BER', labels=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2cpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
