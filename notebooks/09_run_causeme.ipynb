{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import zipfile\n",
    "import bz2\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.d2c.utils import create_lagged_multiple_ts\n",
    "from src.d2c.d2c import D2C\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_method(data, clf, maxlags, n_variables):\n",
    "    T, N = data.shape\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    lagged_data = create_lagged_multiple_ts([data_df], maxlags) \n",
    "    d2c_test = D2C(None,lagged_data,maxlags=maxlags,n_variables=n_variables)\n",
    "    \n",
    "    X_test = d2c_test.compute_descriptors_no_dags()\n",
    "    test_df = pd.DataFrame(X_test)\n",
    "    test_df = test_df.drop(['graph_id','edge_source','edge_dest'], axis=1)\n",
    "\n",
    "    y_pred = clf.predict_proba(test_df)[:,1]\n",
    "    returned = pd.concat([pd.DataFrame(X_test), pd.DataFrame(y_pred, columns=['is_causal'])], axis=1)\n",
    "    of_interest = returned[['edge_source','edge_dest','is_causal']]\n",
    "\n",
    "    extended_val_matrix = np.zeros((n_variables * (maxlags + 1), n_variables), dtype='float32')\n",
    "    \n",
    "    for _, row in of_interest.iterrows():\n",
    "        source =int(row['edge_source'])\n",
    "        dest = int(row['edge_dest'])\n",
    "        weight = row['is_causal']\n",
    "        extended_val_matrix[source, dest] = weight\n",
    "\n",
    "    val_matrix = np.zeros((N, N), dtype='float32')\n",
    "    lag_matrix = np.zeros((N, N), dtype='float32')\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        for j in range(n_variables):\n",
    "            values = extended_val_matrix[i::n_variables, j] \n",
    "            val_matrix[i, j] = np.max(values)\n",
    "            lag_matrix[i, j] = np.argmax(values)\n",
    "\n",
    "    thresholded_val_matrix = val_matrix.copy()\n",
    "    thresholded_val_matrix[thresholded_val_matrix < 0.5] = 0\n",
    "    thresholded_val_matrix[thresholded_val_matrix >= 0.5] = 1\n",
    "\n",
    "    return val_matrix, 1 - thresholded_val_matrix, lag_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_zip_file(name, _, clf, maxlags=1, n_variables=3):\n",
    "    print(\"\\rRun on {}\".format(name), end='', flush=True)\n",
    "    data = np.loadtxt(name)\n",
    "    \n",
    "    # Runtimes for your own assessment\n",
    "    start_time = time.time()\n",
    "    # Run your method (adapt parameters if needed)\n",
    "    val_matrix, p_matrix, lag_matrix = my_method(data, clf, maxlags,n_variables)\n",
    "    runtime = time.time() - start_time\n",
    "\n",
    "    # Convert the matrices to the required format and return\n",
    "    score = val_matrix.flatten()\n",
    "    pvalue = p_matrix.flatten() if p_matrix is not None else None\n",
    "    lag = lag_matrix.flatten() if lag_matrix is not None else None\n",
    "\n",
    "    return score, pvalue, lag, runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#zip training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_variables_list = [3, 5, 10, 20]\n",
    "# noise_std_list = [0.01,0.1,0.3, 0.5, 0.75]\n",
    "\n",
    "# dfs = []\n",
    "# for i, n_variables in enumerate(n_variables_list):\n",
    "#     for j, noise_std in enumerate(noise_std_list):\n",
    "#         descriptors_path = os.path.join('..','data','synthetic',f'data_N{n_variables}_std{noise_std}/descriptors_var.pkl')\n",
    "\n",
    "#         df = pd.read_pickle(descriptors_path)\n",
    "#         dfs.append(df)\n",
    "\n",
    "# training_data = pd.concat(dfs, axis=0)\n",
    "\n",
    "training_data = pd.read_pickle(os.path.join('..','data','descriptors','training_data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedRandomForestClassifier(max_depth=10, n_estimators=20, n_jobs=1,\n",
       "                               random_state=0, replacement=True,\n",
       "                               sampling_strategy=&#x27;all&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedRandomForestClassifier(max_depth=10, n_estimators=20, n_jobs=1,\n",
       "                               random_state=0, replacement=True,\n",
       "                               sampling_strategy=&#x27;all&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BalancedRandomForestClassifier(max_depth=10, n_estimators=20, n_jobs=1,\n",
       "                               random_state=0, replacement=True,\n",
       "                               sampling_strategy='all')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = training_data.drop(['graph_id', 'edge_source', 'edge_dest', 'is_causal','value','pvalue'], axis=1) #TODO: add VAR to causeme! \n",
    "y_train = training_data['is_causal']\n",
    "clf = BalancedRandomForestClassifier(n_estimators=20, max_depth=10, n_jobs=1, random_state=0,sampling_strategy='all', replacement=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(os.listdir(os.path.join('..','data','causeme')), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on ../results/causeme/unzipped/nonlinear-VAR_N-5_T-300_0175.txt"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in sorted(os.listdir(os.path.join('..','data','causeme')), reverse=True)[:25]:\n",
    "    if not file.endswith('.zip'):\n",
    "        continue\n",
    "\n",
    "    if file == 'TestWEATHnoise_N-5_T-2000.zip':\n",
    "        continue #already processed TODO remove\n",
    "    \n",
    "    results = {}\n",
    "    results['method_sha'] = \"0931a3e645e3436b89c56f5e1274dcb7\"\n",
    "\n",
    "    maxlags = 5 #general \n",
    "    n_variables = int(file.split('N-')[1].split('_')[0])\n",
    "    results['parameter_values'] = \"maxlags=%d\" % maxlags\n",
    "    results['model'] = file.split('_N-')[0]\n",
    "\n",
    "    experimental_setup = file.split(results['model'])[1].split('.zip')[0][1:] #remove the first underscore\n",
    "\n",
    "    results['experiment'] = results['model'] + '_' + experimental_setup\n",
    "\n",
    "    save_name = '{}_{}_{}'.format('d2cpy',results['parameter_values'], results['experiment'])\n",
    "\n",
    "    experiment_folder = os.path.join('..','results','causeme','experiments')\n",
    "    results_folder = os.path.join('..','results','causeme','results')\n",
    "    unzip_folder = os.path.join('..','results','causeme','unzipped')\n",
    "\n",
    "    experiment_zip = os.path.join('..','data','causeme',file)\n",
    "    experiment_results = os.path.join(results_folder,save_name+'.json.bz2')\n",
    "\n",
    "    #################################################\n",
    "\n",
    "    scores = []\n",
    "    pvalues = []\n",
    "    lags = []\n",
    "    runtimes = []\n",
    "\n",
    "    results_from_mp = []\n",
    "\n",
    "    with zipfile.ZipFile(experiment_zip, \"r\") as zip_ref:\n",
    "        #unzip the files and make a list\n",
    "        zip_ref.extractall(unzip_folder)\n",
    "        names = sorted(zip_ref.namelist())\n",
    "    args_list = [(os.path.join(unzip_folder,name), 'd2cpy', clf, maxlags, n_variables) for name in names]\n",
    "\n",
    "    with Pool(processes=20) as pool:\n",
    "        results_from_mp = pool.starmap(process_zip_file, args_list)\n",
    "\n",
    "    scores, pvalues, lags, runtimes = [], [], [], []\n",
    "    for result in results_from_mp:\n",
    "        score, pvalue, lag, runtime = result\n",
    "        scores.append(score)\n",
    "        if pvalue is not None: pvalues.append(pvalue)\n",
    "        if lag is not None: lags.append(lag)\n",
    "        runtimes.append(runtime)\n",
    "\n",
    "    results['scores'] = np.array(scores).tolist()\n",
    "    if len(pvalues) > 0: results['pvalues'] = np.array(pvalues).tolist()\n",
    "    if len(lags) > 0: results['lags'] = np.array(lags).tolist()\n",
    "    results['runtimes'] = np.array(runtimes).tolist()\n",
    "\n",
    "    # Save data\n",
    "    results_json = bytes(json.dumps(results), encoding='latin1')\n",
    "    with bz2.BZ2File(experiment_results, 'w') as mybz2:\n",
    "        mybz2.write(results_json)\n",
    "\n",
    "    # Empty the folder unzip_folder\n",
    "    for file in os.listdir(unzip_folder):\n",
    "        os.remove(os.path.join(unzip_folder,file))\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2cpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
