{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: da riscrivere, il codice va in src \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.benchmark.var import VAR\n",
    "from src.benchmark.d2c_wrapper import D2C\n",
    "from src.benchmark.metrics import make_plots, compute_roc_auc_curves\n",
    "from src.descriptors.d2c_past_gen import DescriptorsGenerator\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import os \n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import statsmodels.tsa.api as tsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_lagged_multiple_ts(observations, maxlags):\n",
    "    #create lagged observations for all the available time series\n",
    "    lagged_observations = []\n",
    "    for obs in observations:\n",
    "        lagged = obs.copy()\n",
    "        for i in range(1,maxlags+1):\n",
    "            lagged = pd.concat([lagged, obs.shift(i)], axis=1)\n",
    "        lagged.columns = [i for i in range(len(lagged.columns))]\n",
    "        lagged_observations.append(lagged.dropna())\n",
    "    return lagged_observations\n",
    "\n",
    "def infer( single_ts, maxlags):\n",
    "    model = tsa.var.var_model.VAR(single_ts.values)\n",
    "    results = model.fit(maxlags=maxlags)\n",
    "    return results\n",
    "\n",
    "def build_causal_df(results, n_variables):\n",
    "    pvalues = results.pvalues\n",
    "    values = results.coefs\n",
    "\n",
    "    #initialization\n",
    "    pairs = [(source, effect) for source in range(n_variables) for effect in range(n_variables)]\n",
    "    multi_index = pd.MultiIndex.from_tuples(pairs, names=['source', 'target'])\n",
    "    causal_dataframe = pd.DataFrame(index=multi_index, columns=['is_causal', 'value', 'pvalue'])\n",
    "\n",
    "    \n",
    "    for source in range(n_variables):\n",
    "        for effect in range(n_variables):\n",
    "            current_pvalue = pvalues[source, effect]\n",
    "            current_value = values[0][effect][source]\n",
    "\n",
    "            is_causal = 0 if current_pvalue > 0.05 else 0 if abs(current_value) < 0.1 else 1\n",
    "            causal_dataframe.loc[(source, effect)] = is_causal, current_value, current_pvalue\n",
    "\n",
    "    return causal_dataframe\n",
    "\n",
    "def process_time_series(args):\n",
    "    generative_process_idx, internal_idx, ts, n_variables, maxlags, loaded_observations, descriptors = args\n",
    "    lenght_data_generative_process = len(loaded_observations[generative_process_idx])\n",
    "    corresponding_graph_id = (generative_process_idx - 1) * lenght_data_generative_process + internal_idx\n",
    "    results = infer(ts, maxlags=1)\n",
    "    causal_df = build_causal_df(results, n_variables * (maxlags + 1))\n",
    "    descriptors_chunk = descriptors.loc[descriptors.graph_id == corresponding_graph_id]\n",
    "    joined_table = pd.merge(descriptors_chunk, causal_df.drop(columns='is_causal'), how='inner', left_on=['edge_source', 'edge_dest'], right_on=['source', 'target'])\n",
    "    return joined_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:28<00:00,  7.43s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.60s/it]\n",
      "/tmp/ipykernel_14928/3844907139.py:3: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  descriptors[n_variables] = {}\n",
      "100%|██████████| 20/20 [02:54<00:00,  8.74s/it]\n",
      "100%|██████████| 20/20 [02:54<00:00,  8.73s/it]\n",
      "/tmp/ipykernel_14928/3844907139.py:3: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  descriptors[n_variables] = {}\n",
      "100%|██████████| 20/20 [03:24<00:00, 10.22s/it]\n",
      "100%|██████████| 20/20 [03:36<00:00, 10.83s/it]\n",
      "/tmp/ipykernel_14928/3844907139.py:3: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  descriptors[n_variables] = {}\n",
      "100%|██████████| 20/20 [04:43<00:00, 14.19s/it]\n",
      "100%|██████████| 20/20 [04:53<00:00, 14.66s/it]\n"
     ]
    }
   ],
   "source": [
    "descriptors = {}\n",
    "for n_variables in [3,5,10,20]:\n",
    "        descriptors[n_variables] = {}\n",
    "        for noise_std in [0.5,0.75]:\n",
    "            maxlags = 3\n",
    "            output_folder = f'data/synthetic/data_N{n_variables}_std{noise_std}/'\n",
    "            file_name = 'descriptors_Ridgefamily-0-1-2-3-4-5.pkl'\n",
    "\n",
    "            descriptors = pd.read_pickle('../'+output_folder + file_name)\n",
    "\n",
    "            data_path = output_folder\n",
    "            loaded_observations = {}\n",
    "            loaded_dags = {}\n",
    "            loaded_causal_dfs = {}\n",
    "            for file in os.listdir('../'+data_path):\n",
    "                if file.startswith('data'):\n",
    "                    index = file.split('_')[1].split('.')[0]\n",
    "                    with open('../'+data_path+file, 'rb') as f:\n",
    "                        loaded_observations[int(index)], loaded_dags[int(index)], loaded_causal_dfs[int(index)], _ = pickle.load(f)\n",
    "\n",
    "            list_results = []\n",
    "            for generative_process_idx in tqdm(range(1, 21)):\n",
    "                lagged_time_series = create_lagged_multiple_ts(loaded_observations[generative_process_idx], maxlags)\n",
    "                n_jobs = 30\n",
    "                if n_jobs == 1:\n",
    "                    results = []\n",
    "                    for internal_idx, ts in enumerate(lagged_time_series):\n",
    "                        results.append(process_time_series((generative_process_idx, internal_idx, ts, n_variables, maxlags, loaded_observations, descriptors)))\n",
    "                else:\n",
    "                    with Pool(n_jobs) as pool:\n",
    "                        args = [(generative_process_idx, internal_idx, ts, n_variables, maxlags, loaded_observations, descriptors) for internal_idx, ts in enumerate(lagged_time_series)]\n",
    "                        results = pool.map(process_time_series, args)\n",
    "                list_results.append(results)\n",
    "\n",
    "            list_flat = [item for sublist in list_results for item in sublist]\n",
    "            descriptors_var = pd.concat(list_flat, axis=0)\n",
    "            descriptors_var = descriptors_var[[c for c in descriptors_var if c not in ['is_causal']] + ['is_causal']]\n",
    "            descriptors_var.to_pickle('../'+data_path+'descriptors_var.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2cpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
