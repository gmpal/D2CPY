{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../d2c')\n",
    "from d2c import D2C as D2C_\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../data/deleteme_descriptors.csv')\n",
    "#flattening\n",
    "# df = df[(df['edge_dest'] < 3) & (df['edge_source'] > 2)].sort_values(by=['graph_id','edge_source', 'edge_dest']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1      56\n",
       "Name: is_causal, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_causal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppress fture warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['graph_id','edge_source','edge_dest', 'is_causal'], axis=1)\n",
    "y = df['is_causal']\n",
    "#train test split \n",
    "logo = LeaveOneGroupOut()\n",
    "groups = df['graph_id']\n",
    "brf_scores = pd.DataFrame(columns=['accuracy_train','precision_train','recall_train', 'f1_train', 'auc_train', 'accuracy_test', 'precision_test', 'recall_test', 'f1_test', 'auc_test'])\n",
    "counter = 0\n",
    "predicted_values = {}\n",
    "predicted_probabilities = {}\n",
    "real_values = {}\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    current_group = groups[test_index[0]]\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    brf = BalancedRandomForestClassifier(n_estimators=10, max_depth=10, random_state=0, n_jobs=10)\n",
    "    brf.fit(X_train, y_train)\n",
    "\n",
    "    accuracy_train = brf.score(X_train, y_train)\n",
    "    precision_train = precision_score(y_train, brf.predict(X_train))\n",
    "    recall_train = recall_score(y_train, brf.predict(X_train))\n",
    "    f1_train = f1_score(y_train, brf.predict(X_train))\n",
    "    auc_train = roc_auc_score(y_train, brf.predict_proba(X_train)[:,1])\n",
    "\n",
    "    y_hat = brf.predict(X_test)\n",
    "    y_hat_proba = brf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "\n",
    "    accuracy_test = brf.score(X_test, y_test)\n",
    "    precision_test = precision_score(y_test, y_hat)\n",
    "    recall_test = recall_score(y_test, y_hat)\n",
    "    f1_test = f1_score(y_test, y_hat)\n",
    "    auc_test = roc_auc_score(y_test, y_hat_proba)\n",
    "\n",
    "    predicted_values[len(brf_scores)] = y_hat\n",
    "    predicted_probabilities[len(brf_scores)] = y_hat_proba\n",
    "    real_values[len(brf_scores)] = y_test\n",
    "\n",
    "\n",
    "    brf_scores.loc[len(brf_scores)] = [accuracy_train, precision_train, recall_train, f1_train, auc_train, accuracy_test, precision_test, recall_test, f1_test, auc_test]\n",
    "\n",
    "\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    if counter == 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.632035</td>\n",
       "      <td>0.124675</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.220183</td>\n",
       "      <td>0.908542</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.428346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.627706</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.934349</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.360656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.122010</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.216561</td>\n",
       "      <td>0.920542</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.650433</td>\n",
       "      <td>0.118132</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.210269</td>\n",
       "      <td>0.912805</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.388054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.107579</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.898045</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.496387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.112867</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.201613</td>\n",
       "      <td>0.888222</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.633075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490260</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.166372</td>\n",
       "      <td>0.913230</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.410282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.588745</td>\n",
       "      <td>0.112412</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.926939</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.429143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  precision_train  recall_train  f1_train  auc_train  \\\n",
       "0        0.632035         0.124675      0.941176  0.220183   0.908542   \n",
       "1        0.627706         0.117949      1.000000  0.211009   0.934349   \n",
       "2        0.600649         0.122010      0.962264  0.216561   0.920542   \n",
       "3        0.650433         0.118132      0.955556  0.210269   0.912805   \n",
       "4        0.601732         0.107579      0.936170  0.192982   0.898045   \n",
       "5        0.571429         0.112867      0.943396  0.201613   0.888222   \n",
       "6        0.490260         0.090909      0.979167  0.166372   0.913230   \n",
       "7        0.588745         0.112412      0.979592  0.201681   0.926939   \n",
       "\n",
       "   accuracy_test  precision_test  recall_test   f1_test  auc_test  \n",
       "0       0.537879        0.017241     0.200000  0.031746  0.428346  \n",
       "1       0.522727        0.050847     0.300000  0.086957  0.360656  \n",
       "2       0.454545        0.000000     0.000000  0.000000  0.260982  \n",
       "3       0.568182        0.074074     0.363636  0.123077  0.388054  \n",
       "4       0.515152        0.089552     0.666667  0.157895  0.496387  \n",
       "5       0.659091        0.022727     0.333333  0.042553  0.633075  \n",
       "6       0.409091        0.051282     0.500000  0.093023  0.410282  \n",
       "7       0.583333        0.038462     0.285714  0.067797  0.429143  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.660012</td>\n",
       "      <td>0.824789</td>\n",
       "      <td>0.588223</td>\n",
       "      <td>0.686703</td>\n",
       "      <td>0.765943</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.488235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644602</td>\n",
       "      <td>0.811434</td>\n",
       "      <td>0.571873</td>\n",
       "      <td>0.670910</td>\n",
       "      <td>0.749656</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.380682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658436</td>\n",
       "      <td>0.817084</td>\n",
       "      <td>0.593683</td>\n",
       "      <td>0.687695</td>\n",
       "      <td>0.758713</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.452941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.664565</td>\n",
       "      <td>0.820692</td>\n",
       "      <td>0.601977</td>\n",
       "      <td>0.694522</td>\n",
       "      <td>0.766502</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.605882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.644602</td>\n",
       "      <td>0.817301</td>\n",
       "      <td>0.565407</td>\n",
       "      <td>0.668409</td>\n",
       "      <td>0.752105</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.652220</td>\n",
       "      <td>0.817695</td>\n",
       "      <td>0.580159</td>\n",
       "      <td>0.678745</td>\n",
       "      <td>0.754947</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.648542</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.572821</td>\n",
       "      <td>0.673685</td>\n",
       "      <td>0.753081</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.414474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.649899</td>\n",
       "      <td>0.813676</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>0.677215</td>\n",
       "      <td>0.757277</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.849206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.638911</td>\n",
       "      <td>0.809804</td>\n",
       "      <td>0.561830</td>\n",
       "      <td>0.663402</td>\n",
       "      <td>0.743900</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.647010</td>\n",
       "      <td>0.812506</td>\n",
       "      <td>0.575605</td>\n",
       "      <td>0.673840</td>\n",
       "      <td>0.746880</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.642063</td>\n",
       "      <td>0.807704</td>\n",
       "      <td>0.570935</td>\n",
       "      <td>0.668988</td>\n",
       "      <td>0.746463</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.635802</td>\n",
       "      <td>0.811948</td>\n",
       "      <td>0.553214</td>\n",
       "      <td>0.658062</td>\n",
       "      <td>0.740384</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.448864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.653183</td>\n",
       "      <td>0.828136</td>\n",
       "      <td>0.570885</td>\n",
       "      <td>0.675859</td>\n",
       "      <td>0.758533</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.644427</td>\n",
       "      <td>0.817727</td>\n",
       "      <td>0.564388</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0.750344</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.523026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.636941</td>\n",
       "      <td>0.813229</td>\n",
       "      <td>0.554050</td>\n",
       "      <td>0.659075</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.647141</td>\n",
       "      <td>0.812665</td>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.673922</td>\n",
       "      <td>0.754887</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.659618</td>\n",
       "      <td>0.823069</td>\n",
       "      <td>0.589329</td>\n",
       "      <td>0.686858</td>\n",
       "      <td>0.766156</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.576471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.657998</td>\n",
       "      <td>0.818425</td>\n",
       "      <td>0.591264</td>\n",
       "      <td>0.686542</td>\n",
       "      <td>0.760586</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.570588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.647229</td>\n",
       "      <td>0.819432</td>\n",
       "      <td>0.568318</td>\n",
       "      <td>0.671156</td>\n",
       "      <td>0.753992</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.770588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.647097</td>\n",
       "      <td>0.816932</td>\n",
       "      <td>0.570836</td>\n",
       "      <td>0.672064</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.585227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_train  precision_train  recall_train  f1_train  auc_train  \\\n",
       "0         0.660012         0.824789      0.588223  0.686703   0.765943   \n",
       "1         0.644602         0.811434      0.571873  0.670910   0.749656   \n",
       "2         0.658436         0.817084      0.593683  0.687695   0.758713   \n",
       "3         0.664565         0.820692      0.601977  0.694522   0.766502   \n",
       "4         0.644602         0.817301      0.565407  0.668409   0.752105   \n",
       "5         0.652220         0.817695      0.580159  0.678745   0.754947   \n",
       "6         0.648542         0.817662      0.572821  0.673685   0.753081   \n",
       "7         0.649899         0.813676      0.579952  0.677215   0.757277   \n",
       "8         0.638911         0.809804      0.561830  0.663402   0.743900   \n",
       "9         0.647010         0.812506      0.575605  0.673840   0.746880   \n",
       "10        0.642063         0.807704      0.570935  0.668988   0.746463   \n",
       "11        0.635802         0.811948      0.553214  0.658062   0.740384   \n",
       "12        0.653183         0.828136      0.570885  0.675859   0.758533   \n",
       "13        0.644427         0.817727      0.564388  0.667839   0.750344   \n",
       "14        0.636941         0.813229      0.554050  0.659075   0.745763   \n",
       "15        0.647141         0.812665      0.575644  0.673922   0.754887   \n",
       "16        0.659618         0.823069      0.589329  0.686858   0.766156   \n",
       "17        0.657998         0.818425      0.591264  0.686542   0.760586   \n",
       "18        0.647229         0.819432      0.568318  0.671156   0.753992   \n",
       "19        0.647097         0.816932      0.570836  0.672064   0.750976   \n",
       "\n",
       "    accuracy_test  precision_test  recall_test   f1_test  auc_test  \n",
       "0        0.555556        0.692308     0.529412  0.600000  0.488235  \n",
       "1        0.370370        0.461538     0.375000  0.413793  0.380682  \n",
       "2        0.555556        0.631579     0.705882  0.666667  0.452941  \n",
       "3        0.555556        0.666667     0.588235  0.625000  0.605882  \n",
       "4        0.481481        0.555556     0.333333  0.416667  0.450000  \n",
       "5        0.814815        0.944444     0.809524  0.871795  0.841270  \n",
       "6        0.481481        0.777778     0.368421  0.500000  0.414474  \n",
       "7        0.666667        0.928571     0.619048  0.742857  0.849206  \n",
       "8        0.481481        0.692308     0.473684  0.562500  0.552632  \n",
       "9        0.555556        0.625000     0.625000  0.625000  0.454545  \n",
       "10       0.592593        0.700000     0.466667  0.560000  0.616667  \n",
       "11       0.407407        0.500000     0.375000  0.428571  0.448864  \n",
       "12       0.666667        0.857143     0.631579  0.727273  0.802632  \n",
       "13       0.333333        0.600000     0.157895  0.250000  0.523026  \n",
       "14       0.703704        0.750000     0.833333  0.789474  0.611111  \n",
       "15       0.666667        0.833333     0.588235  0.689655  0.729412  \n",
       "16       0.555556        0.777778     0.411765  0.538462  0.576471  \n",
       "17       0.481481        0.714286     0.294118  0.416667  0.570588  \n",
       "18       0.555556        0.857143     0.352941  0.500000  0.770588  \n",
       "19       0.518519        0.666667     0.375000  0.480000  0.585227  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
